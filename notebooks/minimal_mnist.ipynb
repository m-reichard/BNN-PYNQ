{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Minimal MNIST example for BNN-PYNQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this notebook we'll use the LFC overlay, which has binarized activations and three hidden layers with 1024 binarized neurons, to classify handwritten digits.\n",
    "\n",
    "## Set up the overlay and network parameters\n",
    "We start by instantiating the overlay, and checking which networks are available. We then load the parameters for the **mnist** network, and print the classes that this network can recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import bnn\n",
    "c = bnn.PynqBNN(network = bnn.NETWORK_LFC)\n",
    "print(\"Available parameters for LFC overlay: \" + str(bnn.available_params(bnn.NETWORK_LFC)))\n",
    "c.load_parameters(\"mnist\")\n",
    "print(\"Classes for MNIST network: \" + str(c.classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classify a single preprocessed image from the MNIST test set\n",
    "\n",
    "Let's try one of the images from the MNIST test set. We can load and display the image using PIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# load image using PIL and convert to black and white\n",
    "img_7 = Image.open(\"7.png\").convert(\"L\")\n",
    "img_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify I/O, BNN-PYNQ expects images to be delivered in the format that the MNIST dataset uses for distribution. The **image_to_mnist** function can take care of this conversion for us. Once we have the MNIST-formatted data, we can call the **inference** function with the filename to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"7-mnist-formatted\", \"wb\") as fp:\n",
    "  c.image_to_mnist(img_7, fp)\n",
    "ret_7 = c.inference(\"7-mnist-formatted\")\n",
    "ret_7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification result was correct, but how does the performance compare when running this network in pure software instead of the FPGA accelerator? We can instantiate another classifier that uses a pure software implementation to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "c_sw = bnn.PynqBNN(network=bnn.NETWORK_LFC,runtime=bnn.RUNTIME_SW)\n",
    "c_sw.load_parameters(\"mnist\")\n",
    "ret_sw = c_sw.inference(\"7-mnist-formatted\")\n",
    "ret_sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a significant speedup by using the accelerator. In fact, if we classify multiple images in one go, the FPGA accelerator will run even faster. We'll verify this in a later experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classifying a black-on-white handwritten digit\n",
    "\n",
    "The following images were created by drawing them in Pinta (a Paint-like image editor) with a regular mouse, then taking a screenshot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_6 = Image.open(\"6_bw.png\").convert(\"L\")\n",
    "img_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"6-mnist-formatted\", \"wb\") as fp:\n",
    "  # set invert=True since MNIST expects white-on-black\n",
    "  c.image_to_mnist(img_6, fp, invert=True)\n",
    "ret_6 = c.inference(\"6-mnist-formatted\")\n",
    "ret_6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Does it work with some noise?\n",
    "The following was also drawn in Pinta, with some random dots (noise) added to see how the classifier copes with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "img_5 = Image.open(\"5.png\").convert(\"L\")\n",
    "img_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"5-mnist-formatted\", \"wb\") as fp:\n",
    "  # set invert=True since MNIST expects white-on-back\n",
    "  c.image_to_mnist(img_5, fp, invert=True)\n",
    "ret_5 = c.inference(\"5-mnist-formatted\")\n",
    "ret_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Classifying the entire MNIST test set\n",
    "\n",
    "Let's verify the accuracy (and performance) of this network using the entire MNIST test set. We'll start by downloading and unzipping the MNIST test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!wget -nc http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz; gunzip -f t10k-images-idx3-ubyte.gz\n",
    "!wget -nc http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz; gunzip -f t10k-labels-idx1-ubyte.gz\n",
    "!ls *ubyte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can pass the test set images directly to the **inference_multiple** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ret_test = c.inference_multiple(\"t10k-images-idx3-ubyte\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "By passing a large amount of images at once, the accelerator can run much faster, around 150 thousand images per second. But what about the correctness of the returned results? To verify the correctness of the classifications, we'll load the \"answer key\" and compare it against what was returned by the accelerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"t10k-labels-idx1-ubyte\", 'rb') as f:\n",
    "  ret_test_golden = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "np.unique(ret_test_golden == ret_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
